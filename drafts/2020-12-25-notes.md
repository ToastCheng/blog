
malloc overcommit
lazy allocation, virtual memory

dpdk telecom
grep -r <pattern> *
cloc: count line of code 
nm: list symbols from object file
bloom filter 粗排再細排
valgrind 抓漏神器 動態分析的系統軟體框架
- massif

軟體interrupt:
system call
硬體interrupt:
timer
low battery

memory order: out-of-order execution
就算編譯器產生的指令是符合預期的，現代的處理器也不一定會照順序執行
因為cpu快 記憶體慢，讓cpu不要被記憶體拖慢
為了讓資料一致，需要memory barrier
> when the memory is shared with multiple devices, such as other CPUs in a multiprocessor system, or memory-mapped peripherals, out-of-order access may affect program behavior.
>

Kernel space <-> User space
copy_to_user
copy_from_user

wpa_supplicant

/proc/interrupts
/proc/irq

intel turbo mode 會讓運算速度浮動

rdtsc: intel 指令
timestamp counter

hrt: high resolution timer
是額外的硬體，精準度可以高很多

ktime_get

unlikely: gcc __builtin_expect
branch prediction macro
`#define likely(x) __builtin_expect(!!(x), 1)`
`#define unlikely(x) __builtin_expect(!!(x), 0)`
```
if (unlikely(condition)) {
    // 告訴編譯器這個block很少執行，可以把這一段放到後面以加速
}
```

procfs
著重訊息揭露以及從user space得到訊息

使用sysfs把kernel的(執行時期的)資訊揭露到user space
kobject
e.g. 
`ls /sys/kernel/irq`
`cat /sys/kernel/irq/1/name`

psuedo file system
virtual file system
psuedo: 不具備真實的要件
virtual: 具備真實的要件

在user space用printf
在kernel space用printk
printk成本高

ring buffer 
lockless
lockfree

printk顯示的就是dmesg
訊息完整顯示不會被截斷，代表printk有mutex lock
printf只顯示buffer內的資訊

taskset 固定在一個cpu上
`/boot/grub/grub.cfg`
`isolcpus=0`

## Linux 核心設計 : 作業系統術語及概念 (2020-03-02)

Netflix 用linux, FreeBSD
linux通用
FreeBSD儲存功能

FUSE: file system in user space
nstack: network in user space

trusty TEE

single system image

IPA: intermediate 
virtual address -> ipa -> physical address
ksm: kernel samepage merge

kernel / user space 1: 1, 1: 3 

zombie process
佔著資源 

process的execution mode，意味著可以執行的指令，kernel mode較多

execution context
- process context
    - code runs in user mode: process
    - code runs in kernel mode: system call issued by a process
- interrupt context
    - code that runs as a result of an interrupt
    - always in kernel mode

smp: symmetric multiple processor 對稱多處理器
每個處理器都有kernel
asmp: asymmetric multiple processor
kernel執行在某一處理器，其他處理器跑user process

rsu:

記憶體管理器:
slob/slab/slub

fork, exec, clone

inode: information node

domain socket

capability: concept borrow from microkernel
在特定時間下資源限制的給予process能力

netns 虛擬網路 namespace

# Linux 核心設計 : 以 User Mode Linux 進行開發及分析 (2020-2-8)
user mode linux, run在user mode的linux 
方便測試 gdb

linux 測試框架：
- linux kernel self test
- kunit

best case:
compute intensive, no too many system calls, context switches
worst case:
IO

early printk, circular buffer:
剛開機時，os可能就有東西要print，但device可能還沒載入，這時就會把log存到一段記憶體位置中
實作上是ring buffer，log太多會有遺失
而uml則直接用printf, nothing to lose

ptrace: 用process a去read/write process b的內容

page fault:
- minor: 最常見, caching找不到, mmap
lazy allocation之所以能成功 要歸功minor page fault
一開始宣吿某個數量的空間 但真正存取總是在一段時間之後
可以利用這個特性 晚一點再真的配置記憶體
需要mmu 的配合
作業系統告訴mmu 在某些page可以不用馬上對應 (virtual address)
因此會觸發minor page fault
觸發page fault handler
:page已經被載入記憶體 但mmu 沒有將這個page標記為loaded

- major: memory找不到去swap找

- invalid: null pointer is a pointer to address 0.
多數的作業系統會去設定mmu， 把這個區域標示為不可讀不可寫不可執行

lkl: linux kernel library
很多原本只在kernel跑的程式像是bootloader，因為虛擬化、容器等新技術也需要在user space跑

kvm zero copy
aws 有時候 在台灣連美國機器比連台灣機器還快？
aws 有時候 連a再連b比直接連b快？

virtio
為host和guest端提供虛擬介面 讓彼此可以交流

busybox linux 工具們


虛擬網卡 tun/tap

## Linux 核心設計：不只挑選任務的排程器 (一) (2019-03-04)

難在安插任務到適合的位置
 
schedule: 任務 -> 資源

mmu: memory management unit

oversubscribed: 待處理任務的數量往往遠大於資源的總量

perf
`perf bench sched pipe`

taskset: affinity到特定core
`taskset -c 0 perf bench sched pipe`

numactl
不同cpu核心間的距離會不同，taskset可以限定process跑在同一個核心，效能可能較好

bitmap scheduler

O(1)
CFS: completely fair scheduler

何時可以搶佔？
跟優先有關
- 系統呼叫前，離開user space時
- 系統呼叫中，不是每個系統呼叫都可以被搶佔，只有較耗時的會，如FSYNC
- 系統呼叫後，回到user space之前，可以被搶佔，重新排程
- 中斷，timer interrupt

task_struct 很神奇的資料結構
> kernel thread just borrows previous task's mm, as they only execute in kernel space.
>

fork  - create a child process
vfork - create a child process and block parent 鳩佔鵲巢

coroutine:
setjmp 指定,
longjmp 跳到之前指定的位置
這種機制，是協同cooperative的，context switch會是程式在特定場合自發的呼叫longjmp

- guarantee delivery
- best-effort delivery (with QoS)


BookKeeping
2 * 40 * #CPU
- 2 set of runqueue per cpu
- 40 priority level

O(1) scheduling
`unordered_map<int, queue<Task>> active`
`unordered_map<int, queue<Task>> expired`
```
active:           expired:
139: t -> t -> t  139:
138: t            138:
137:              137:
136: t -> t       136:
135:              135:
```
1. take the lowest value (highest priority)
```
active:           expired:
139: t -> t -> t  139:
138: t            138:
137:              137:
136: (t1) -> t2   136:
135:              135:
```
2. when done, recompute its priority and put it on the expire set
```
active:           expired:
139: t -> t -> t  139:
138: t            138:
137:              137:
136: t2           136:
135:              135: t1
```
3. once active is completey empty, swap active and expire set.
4. O(1) since fixed number of queue to scan.

constant QUERY time, 但修改刪除有額外開銷

Q: if task is blocked, such as on disk IO?

EAS: energy aware system


--- 
semaphore: an unsigned integer, with two operations
`wait()` and `post()`
```
wait() {
    while(1) {
        atomic {
            if (v>0) {
                v--;
                return;
            }
        }
    }
}
```
```
post() {
    atomic {
        v++;
        return;
    }
}
```
counter -> 還可以進入的名額
wait -> 像accuire
post -> 像release

把它當作mutex來用的話
```
wait()
// critical section
post()
```
但semaphore沒有持有者的概念！也就是說今天可以有另一個thread直接呼叫post來增加一個名額



semaphore事實上是個counter，決定多少人可以進去
當process看到semaphore的counter是0時，就能知道自己無法獲取資源，可以進入sleep
如果是用spin lock，就得空轉等待

mutex有持有者的概念

### cache line bouncing
cache一次讀就是一排cache line
cpu核數越多cache miss cost越大

mount table

atomic instruction 不保證 clock cycle

sloppy counters

linux reference count

dentry: vfs 像是inode

mimalloc: microsoft research, truly lock free

### branch miss:
https://en.wikipedia.org/wiki/Branch_predictor
> Without branch prediction, the processor would have to wait until the conditional jump instruction has passed the execute stage before the next instruction can enter the fetch stage in the pipeline. The branch predictor attempts to avoid this waste of time by trying to guess whether the conditional jump is most likely to be taken or not taken.
>

>
Modern microprocessors tend to have quite long pipelines so that the misprediction delay is between 10 and 20 clock cycles.
>

記憶體存取很快，但仍無法和處理器的指令執行速度相提並論。為了從記憶體中讀取指令 (instruction) 和資料 (data)，處理器需要等待，用處理器的時間來衡量，這種等待非常漫長。

### cpu pipeline
https://en.wikipedia.org/wiki/Instruction_pipelining#:~:text=A%20pipelined%20computer%20usually%20has,instruction%20on%20each%20clock%20cycle.

IBM: fetch, decode, execute
RISC: 
1. fetch
2. decode
3. execute
4. memory access
5. write back

1. fetch the operands
2. decode
3. do the instruction
4. write back

```
| instr\cycle | 1   | 2   | 3   | 4   | 5   | 6   | 7   |
| ----------- | --- | --- | --- | --- | --- | --- | --- |
| 1           | IF  | ID  | EX  | MEM | WB  |     |     |
| 2           |     | IF  | ID  | EX  | MEM | WB  |     |
| 3           |     |     | IF  | ID  | EX  | MEM | WB  |
| 4           |     |     |     | IF  | ID  | EX  | MEM |
| 5           |     |     |     |     | IF  | ID  | EX  |
```
此外，在處理器內部，不同指令所需要的執行時間和時鐘週期是不同的，如果嚴格按照程序的執行順序執行，那麼就無法充分利用處理器的 pipeline。因此指令有可能被亂序執行 (out-of-order execution)。

pipeline的假設：
上述三種平行技術對所執行的指令有一個基本要求，即相鄰的指令相互沒有依賴關係。假如某條指令需要依賴前面一條指令的執行結果數據，那麼 pipeline 便失去作用，因為第二條指令必須等待第一條指令完成。因此好的軟體必須儘量避免產生這種程式碼。

branch prediction 指令對軟體效能影響較大。尤其是當處理器採用流水線設計之後，假設 pipeline 有三級，且目前進入 pipeline 的第一道指令為分支 (branch) 指令。假設處理器順序讀取指令，那麼如果分支的結果是跳躍到其他指令，那麼被處理器 pipeline 所 fetch 的後續兩條指令勢必被棄置 (來不及執行)，從而影響性能。為此，很多處理器都提供了 branch prediction，根據同一條指令的歷史執行記錄進行預測，讀取最可能的下一條指令，而並非順序讀取指令。


PMU (performance monitor unit)。
PMU 允許硬體針對某種事件設置 counter

Tracepoint 是散落在核心原始程式碼的一些 hook，一旦使能，在指定的程式碼被運行時，tracepoint 就會被觸發，這樣的特性可被各種 trace/debug 工具所使用，perf 就是這樣的案例。

perf usage:
hardware : 由 PMU 產生的事件，比如 
- cache-misses
- cpu-cycles
- instructions
- branch-misses …等等，通常是當需要瞭解程序對硬體特性的使用情況時會使用。
software : 是核心程式產生的事件，比如 
- context-switches
- page-faults
- cpu-clock
- cpu-migrations …等等。
tracepoint : 是核心中的靜態 tracepoint 所觸發的事件，這些 tracepoint 用來判斷在程式執行時期，核心的行為細節，比如 slab 記憶體配置器的配置次數等。

Commands:
- perf top
[.]表示其位於 User mode，[k]則為 kernel mode
觀察特定事件，e.g. cache-misses 取樣5000/sec
`perf top -e cache-misses -c 5000`

- perf stat
`perf stat --repeat 5 -e cache-misses,cache-references,instructions,cycles ./<program>`

- perf report


動態：priority 
idea: infer from sleep time
- monitor IO wait time to infer which programs are GUI
- give these programs a priority boost

靜態：nice 值
-20 ~ 19
19最nice，最容易被欺負，霸佔資源
「佔用資源的傾向」
會是計算動態priority的起始值

Rebalancing
可以用htop觀察

not rebalancing
if things run slower on another CPU
- numa
- hyper thread
    把核的暫存器複製一份，讓一個核有兩個狀態
- multi-core cache behavior

SMP symmetric multiple processor
NUMA
```
cpu0 cpu1   cpu2 cpu3
  memory1     memory2
``` 

setpriority
getpriority 
---
Trusted computing base (TCB)
信任最小單位
越小越可控、越精準

SELinx 美國國防部擴張
把權限切得很細


---
CFS:
what is fair scheduling?
- interactive / batch job
- priorities
- CPU topology
- Per-user fairness

idea:
- conceptually list of tasks
- ordered by how much time lhey have
- always pick the neediest task to run

list -> (v)RB Tree, AVL Tree
AVL Tree is also a RB Tree
AVL Tree height: log(n)
RB Tree  height: <= 2 * log(n+1)
Worst case: RB > AVL

//Brain Fuck Scheduling

### timer 
global virtual clock
glocal virtual clock ticks once every N real ticks, N is the number of tasks.
each task counts how many clock ticks it has had


### realtime 排程 1-99
do the modest amount of work by a deadline.
- audio application
- 不能太快或太慢

2:25:39
降低重要任務超過deadline的機會: kernel preemption

disable preemption 部分的process不允許被 preempt
EDA: earliest deadline first

Rate montonic scheduling (RMS)
週期性任務

metasploit
4ee870b7afa67f46aeba5085db1f9237626dd85922ba4c5eb565129c0222e3e8e9ce76a596b26af9

### malloc
用sbrk (set break) 和mmap實作
sbrk: 變更特定區域 -> 將heap的邊界往外推

呼叫時不會佔用實體記憶體，只維護虛擬地址 真正需要時才分配實體記憶體 (Copy-on-Write)


```
高(ff)                                                         低(00)
 kernel | stack-> | memory  | <-heap | bss     | data    | text    |
        |         | mapping |        | segment | segment | segment |
        |         | segment |        |         |         |         |
        |         | (dynamic lib)

```
data segment
bss segment
text segment: 機械碼 (ro)
data segment: data (rw)
null pointer: 0 (不可讀,寫,執行)

mpu: memory protection unit

bootmem

device tree

slab: 一種cacheing
跟buddy先叫一些記憶體，然後再分給process，中盤商
不足以支援numa架構

slab -> slub

slub -> slob

vmalloc 組合fragment

kernel有很多種allocator
GEM 管理gpu記憶體


/proc/id/maps
https://stackoverflow.com/questions/1401359/understanding-linux-proc-id-maps

Each row in /proc/$PID/maps describes a region of contiguous virtual memory in a process or thread. Each row has the following fields:
```
address           perms offset  dev   inode   pathname
08048000-08056000 r-xp 00000000 03:0c 64593   /usr/sbin/gpm
```
You might notice a lot of anonymous regions. These are usually created by mmap but are not attached to any file. They are used for a lot of miscellaneous things like shared memory or buffers not allocated on the heap. For instance, I think the pthread library uses anonymous mapped regions as stacks for new threads.

getunwind
 
