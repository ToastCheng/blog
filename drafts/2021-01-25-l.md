linux as a multithread server
```
process   ------syscall---->   [        ]
                               [ kernel ]
IO device ------interrupt----> [        ]
                               [        ]
Timer     ------interrupt----> [        ]
```
Timer: 特別的維繫作業系統運作
快的耗電
慢的省電

interrupt/exceptions
(irqs) interrupt request lines
(pic) programmable interrupt controllers
(idt) interrupt descriptor table
interrupt 
softIRQ, tasklet
workqueue

apic 多核

assigning vector to irq
vector: index 0-255 into idt

index = irq# + 32
- 0-32 non-maskable intr & exceptions
- 128: syscall
- 251-255 ipi 

idt: 
其他架構: 存handler位置
arm架構: 直接存指令

nested intr: stack...?? yes

interrupt handler
- critical: top-half (intr disable)
    - ackowledge intr
- non-c: top-half (intr enabled)
    - read key scan mode
- non-c deferrable: bottom-half, soft irq 降低intr延遲
    - cp keyboard buffer to terminal

top-half: 要趕快執行的
interrupt preemption

bottom-half: 
  - soft irq
  - tasklet
    - 建構在soft_irq之上，也是個function
    - atomic
    - non-preempt
  - work queue
    適用於比較複雜，work queue 較適用於file system, 網路
`cat /proc/ioports`
`cat /proc/interrupts`
`cat /proc/stat`


threaded IRQ
interrupt ---> 本質上是 context switch

---

stream IO
讀寫都各有 buffer

預設 file descriptor:
stdin = 0
stdout = 1
stderr = 2

EOF 字元
EOF macro

signal 是對 exception 的包裝


---
## Linux 核心設計：淺談同步機制 (2018-11-22)
https://hackmd.io/@sysprog/linux-sync

block: 直接把 process 丟進 wait queue，不讓他在 cpu 浪費資源，但需要額外管理

block: mutex, semaphore
non-blocking: spinlock

why 2 loop for spinlock?
Test & Test & Set lock
avoiding cache invalidate, cache line bouncing


cache invalidate:
每個 cpu 可能有獨立的 L1 cache， L2 可能多個 cpu 共用，如果資料更新了，L1 的 cache 會需要 invalidate

cache line bouncing:
一直 cache invalidate

```
while (0 != atomic_dec(&lock->counter)) {
  do {
    // pause cpu until some coherence traffic
    // avoiding cache line bouncing...
  } while (lock->counter <= 0)
}
```

RCU fine grained
RCU 可以體現在 list / hash table 的實作上

# 同步
lock, semaphore
RCU
https://kukuruku.co/post/lock-free-data-structures-the-inside-rcu/

ABA problem
https://en.wikipedia.org/wiki/ABA_problem
thread 把變數 x 寫成 B 再改回 A，另一 thread 可能以為 x 一直都是 A，依照這個事實進行錯誤的邏輯

https://www.youtube.com/watch?v=ZQFzMfHIxng&ab_channel=CppCon
atomic cache line
CPUs 共用 L2/L3 的 cache
是以 cache line 為單位，cache line 可能是 64 bytes 長
如果有個在 cache line 的變數被 CPU2 lock 住，即便 CPU1 沒用到他，但只要他有用到同一個 cache line，就會被 block

`x.fetch_add(1, std::memory_order_relaxed);`
對 processor 或 compiler 沒有任何限制，可以任意交錯的 access memory。

`x.load(std::memory_order_acquire);`
在這個 barrier 之後的任何 operation (ALL reads and writes on ALL variables) 不能跑到 barrier 之前。

`x.store(1, std::memory_order_release);`
在這個 barrier 之前的任何 operation (ALL reads and writes on  ALL variables) 不能跑到 barrier 之後。

https://youtu.be/ZQFzMfHIxng?t=2785
應用:
thread1 writes atomic variable x with release barrier
thread2 reads atomic variable x with acquire barrier

        -------------------------------> Time
thread1  wwww  (release barrier)
thread2        (acquire barrier) rrr

`std::memory_order_acq_rel`

限制 operations 跨越 barrier。

`std:memory_order_seq_cst`

跟程式一樣的順序， default 行為，但效能低


範例:
```
std::atomic<size_t> count;
count.fetch_add(1, std::memory_order_relaxed);
```
單純的計數加總，不會被其他 thread access，所以順序可以有彈性



---
Lec 04 Process Management – Part I
https://www.youtube.com/watch?v=bw3aRZCfsL4&ab_channel=NYCUOCW

system call -> int 0x80 exception
vector table: 不同 exception 該怎麼處理， syscall 屬於其中一個 (0x80)
e.g. x86
| vector range | use                               |
| ------------ | --------------------------------- |
| 0-19         | nonmaskable interrupts/exceptions |
| 20-31        | intel-reserved                    |
| 32-127       | external interrupts IRQs          |
| 128(0x80)    | syscall                           |
| 129-238      | external interrupts IRQs          |

system call table:
system call handler

exception (software)
interrupt (hardware)

Process context
system call 沒有牽涉 context switch，只有 mode 轉換
context 沒有換，因為 kernel 是在幫 user 做事

但 call stack 會分開存放 return，不能共用，避免 user space 存取到 kernel 執行的地址
進入 kernel space 時 sp 會指向 memory 另一部分。
user stack / kernel stack

Lec 05 Process Management – Part II
https://www.youtube.com/watch?v=M69ENFe0Agc&ab_channel=NYCUOCW

Cooperative 合作型:
作業系統提供 api 給 process，只要 process 工作告一段落就 call api 讓出 cpu，信任每個 process。

asynchronous exception (hardware interrupt) --> PIC checks (秘書) ---\
                                                                      --->  vector table ->  service routine
synchronous exception ----------------------------------------------/


觸發 schedule 情境:
1. system call
2. interrupt
3. timer

Interrupt context
cpu 從 process A 接收到 interrupt 時，會進入 interrupt context，非 process A 的 context
但因為 interrupt 發生很頻繁，所以這通常不會是 full scale 的 context switch，也就是說可能只會替換部分 context
盡可能保留 process A 的 context，趕快處理完 interrupt (像 IO)， 再還給 process A。

Q: Kernel 可以被 interrupt 嗎?
早期的 Big Kernel Lock, BKL 即是。
進 kernel 就 lock，閉關做事。

效率更好，但 response time 變差
「你閉關寫論文，但出來老師說不用寫論文」

所以還是會希望 kernel 可以被 interrupt，只要不去觸碰 critical section 即可。

Q: Kernel 可以被 preempt 嗎?
可以，kernel process 也可能被 block，也可能有更高優先級的 peocess。

note: kernel 接受 interrupt 和能被 preempt 是不同問題。

user          | kernel                 blocking
App  -> Lib --|--> Syscall -> klib1 -> disk IO
                                    -> wait for event
                                    -> wait for locked resource

設計上很難。
代表我們假設 kernel 在還沒做完工作時，就可以被 context switch 掉，
可能會有 lock resource 的問題： kernel 持有某些 resource A，被切回 user process B，結果 process B 又 syscall，並試圖取得 resource A
可能造成 dead lock。

解法:
1. 禁止 preempt
2. 沒有 lock 時才允許 preempt


### schedule
優先級（多重要） + 時間（有多少時間）

#### 優先級

nice (0~99) + dynamic priority (-20~19) = total 140
nice value 越大越好被欺負，越不優先

決定 dynamic priority:
- 等很久
- front
- IO-bound
- 不想換 (不用被換 pipeline)

#### 時間 timeslice

|  type    |  nice     | time duration      |
| -------- | --------- | ------------------ |
| initially | parent's | half of parent's   |
| min       | 19       | 5 ms               |
| default   |  0       | 10ms               |
| max       | -20      | 800ms              |

### O(1) scheduler
140 bit array
每個 entry 都是一個 list of runnable tasks
大概像這樣 `vector<list<TaskList>> bitarray (140);`

每次要排程時，找 leading bit O(1)  (最高優先) 的 task list，選 task list 中的第一個
如果高優先 task 沒有 time 了，就執行低優先的。
time interrupt 會負責扣 time。

GDT global descriptive table
LDT local descriptive table

### thread
如果開兩個 word，需要兩個 process 嗎？
兩個 word proecess，有相同 code segment， data segment，但不同 stack
因此可以共用同樣的 code / data segment，各自管理 stack，這就是 thread 的概念

OS thread
- user thread: user 自己管理 thread， kernel 只看到 process
- kernel thread: kernel 可以區分不同的 thread